{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from numpy import array\n",
    "import datetime\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "# define documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40, 11], [12, 36], [17, 44], [13, 36], [31], [19], [17, 44], [14, 12], [17, 36], [6, 36, 11, 38]]\n",
      "[[40 11  0  0]\n",
      " [12 36  0  0]\n",
      " [17 44  0  0]\n",
      " [13 36  0  0]\n",
      " [31  0  0  0]\n",
      " [19  0  0  0]\n",
      " [17 44  0  0]\n",
      " [14 12  0  0]\n",
      " [17 36  0  0]\n",
      " [ 6 36 11 38]]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 4, 8)              400       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 433\n",
      "Trainable params: 433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Accuracy: 80.00%\n"
     ]
    }
   ],
   "source": [
    "docs = ['Well done!',\n",
    "\t\t'Good work',\n",
    "\t\t'Great effort',\n",
    "\t\t'nice work',\n",
    "\t\t'Excellent!',\n",
    "\t\t'Weak',\n",
    "\t\t'Poor effort!',\n",
    "\t\t'not good',\n",
    "\t\t'poor work',\n",
    "\t\t'Could have done better.']\n",
    "# define class labels\n",
    "labels = array([1,1,1,1,1,0,0,0,0,0])\n",
    "# integer encode the documents\n",
    "vocab_size = 50\n",
    "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
    "print(encoded_docs)\n",
    "# pad documents to a max length of 4 words\n",
    "max_length = 4\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "print(padded_docs)\n",
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 8, input_length=max_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "# summarize the model\n",
    "print(model.summary())\n",
    "# fit the model\n",
    "model.fit(padded_docs, labels, epochs=50, verbose=0)\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: {:.2%}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1984, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>UT_id</th>\n",
       "      <th>authors</th>\n",
       "      <th>content</th>\n",
       "      <th>first_author</th>\n",
       "      <th>id</th>\n",
       "      <th>rated</th>\n",
       "      <th>relevant</th>\n",
       "      <th>tag</th>\n",
       "      <th>title</th>\n",
       "      <th>wosarticle__de</th>\n",
       "      <th>wosarticle__wc</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3097</td>\n",
       "      <td>WOS:000364523100021</td>\n",
       "      <td>Poehlein, A, Cebulla, M, Ilg, MM, Bengelsdorf,...</td>\n",
       "      <td>Clostridium aceticum was the first isolated au...</td>\n",
       "      <td>Poehlein, A</td>\n",
       "      <td>581376</td>\n",
       "      <td>2018-09-21 07:54:18.039262+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>760</td>\n",
       "      <td>The Complete Genome Sequence of Clostridium ac...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Microbiology']</td>\n",
       "      <td>2018-09-21 07:54:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>WOS:000276497900007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The increasing number of degraded soil areas c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>323125</td>\n",
       "      <td>2018-09-21 13:09:32.182834+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>760</td>\n",
       "      <td>Evaluating the Potential of Forest Species Und...</td>\n",
       "      <td>Cassiterite mine spoil; Amazon region; Arbuscu...</td>\n",
       "      <td>['Environmental Sciences; Meteorology &amp; Atmosp...</td>\n",
       "      <td>2018-09-21 13:09:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>624</td>\n",
       "      <td>WOS:000207780600001</td>\n",
       "      <td>Liao, IC</td>\n",
       "      <td>Asia is the largest continent in the world. As...</td>\n",
       "      <td>Liao, IC</td>\n",
       "      <td>638275</td>\n",
       "      <td>2018-09-21 09:08:46.626102+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>760</td>\n",
       "      <td>Roles and contributions of fisheries science i...</td>\n",
       "      <td>fisheries science; Asia; capture fisheries; aq...</td>\n",
       "      <td>['Fisheries']</td>\n",
       "      <td>2018-09-21 09:08:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3025</td>\n",
       "      <td>WOS:000297151300006</td>\n",
       "      <td>Sharma, P, Salvato, C</td>\n",
       "      <td>Family firms vary with regards to success achi...</td>\n",
       "      <td>Sharma, P</td>\n",
       "      <td>314899</td>\n",
       "      <td>2018-09-20 11:55:40.780222+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>760</td>\n",
       "      <td>Commentary: Exploiting and Exploring New Oppor...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Business']</td>\n",
       "      <td>2018-09-20 11:55:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>527</td>\n",
       "      <td>WOS:000376697500015</td>\n",
       "      <td>Lozano, R, Nummert, B, Ceulemans, K</td>\n",
       "      <td>An increasing number of companies have, during...</td>\n",
       "      <td>Lozano, R</td>\n",
       "      <td>187272</td>\n",
       "      <td>2018-09-21 02:51:10.396846+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>753</td>\n",
       "      <td>Elucidating the relationship between Sustainab...</td>\n",
       "      <td>Corporate sustainability; Sustainability Repor...</td>\n",
       "      <td>['GREEN &amp; SUSTAINABLE SCIENCE &amp; TECHNOLOGY; En...</td>\n",
       "      <td>2018-09-21 02:51:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                UT_id  \\\n",
       "0        3097  WOS:000364523100021   \n",
       "1         324  WOS:000276497900007   \n",
       "2         624  WOS:000207780600001   \n",
       "3        3025  WOS:000297151300006   \n",
       "4         527  WOS:000376697500015   \n",
       "\n",
       "                                             authors  \\\n",
       "0  Poehlein, A, Cebulla, M, Ilg, MM, Bengelsdorf,...   \n",
       "1                                                NaN   \n",
       "2                                           Liao, IC   \n",
       "3                              Sharma, P, Salvato, C   \n",
       "4                Lozano, R, Nummert, B, Ceulemans, K   \n",
       "\n",
       "                                             content first_author      id  \\\n",
       "0  Clostridium aceticum was the first isolated au...  Poehlein, A  581376   \n",
       "1  The increasing number of degraded soil areas c...          NaN  323125   \n",
       "2  Asia is the largest continent in the world. As...     Liao, IC  638275   \n",
       "3  Family firms vary with regards to success achi...    Sharma, P  314899   \n",
       "4  An increasing number of companies have, during...    Lozano, R  187272   \n",
       "\n",
       "                              rated  relevant  tag  \\\n",
       "0  2018-09-21 07:54:18.039262+00:00         1  760   \n",
       "1  2018-09-21 13:09:32.182834+00:00         1  760   \n",
       "2  2018-09-21 09:08:46.626102+00:00         1  760   \n",
       "3  2018-09-20 11:55:40.780222+00:00         0  760   \n",
       "4  2018-09-21 02:51:10.396846+00:00         1  753   \n",
       "\n",
       "                                               title  \\\n",
       "0  The Complete Genome Sequence of Clostridium ac...   \n",
       "1  Evaluating the Potential of Forest Species Und...   \n",
       "2  Roles and contributions of fisheries science i...   \n",
       "3  Commentary: Exploiting and Exploring New Oppor...   \n",
       "4  Elucidating the relationship between Sustainab...   \n",
       "\n",
       "                                      wosarticle__de  \\\n",
       "0                                                NaN   \n",
       "1  Cassiterite mine spoil; Amazon region; Arbuscu...   \n",
       "2  fisheries science; Asia; capture fisheries; aq...   \n",
       "3                                                NaN   \n",
       "4  Corporate sustainability; Sustainability Repor...   \n",
       "\n",
       "                                      wosarticle__wc                date  \n",
       "0                                   ['Microbiology'] 2018-09-21 07:54:18  \n",
       "1  ['Environmental Sciences; Meteorology & Atmosp... 2018-09-21 13:09:32  \n",
       "2                                      ['Fisheries'] 2018-09-21 09:08:46  \n",
       "3                                       ['Business'] 2018-09-20 11:55:40  \n",
       "4  ['GREEN & SUSTAINABLE SCIENCE & TECHNOLOGY; En... 2018-09-21 02:51:10  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('docs.csv').sample(frac=1).reset_index(drop=True)\n",
    "df['date'] = df['rated'].apply(lambda x: datetime.datetime.strptime(x[:19],\"%Y-%m-%d %H:%M:%S\"))\n",
    "df = df[df['date'] > datetime.datetime(2018,6,1,0,0,0)].reset_index(drop=True)\n",
    "print(df.shape)\n",
    "y = df['relevant']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 500, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 50000)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 50001     \n",
      "=================================================================\n",
      "Total params: 1,050,001\n",
      "Trainable params: 1,050,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "docs = array(df['content'])\n",
    "labels = array(df['relevant'])\n",
    "\n",
    "vocab_size = 10000\n",
    "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
    "\n",
    "# pad documents to a max length of 4 words\n",
    "max_length = 500\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "\n",
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 100, input_length=max_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "# summarize the model\n",
    "print(model.summary())\n",
    "# fit the model\n",
    "model.fit(padded_docs, labels, epochs=50, verbose=0)\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: {:.2%}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1488"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = array(df['content'])\n",
    "labels = array(df['relevant'])\n",
    "\n",
    "vocab_size = 10000\n",
    "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
    "\n",
    "# pad documents to a max length of 4 words\n",
    "max_length = 500\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.model_selection\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "        sklearn.model_selection.train_test_split(padded_docs, labels, random_state=1)\n",
    "\n",
    "len(X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1488, 500)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 500, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 150000)            0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 150001    \n",
      "=================================================================\n",
      "Total params: 3,150,001\n",
      "Trainable params: 3,150,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 300, input_length=max_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, input_dim=200, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "# summarize the model\n",
    "print(model.summary())\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, epochs=50, verbose=0)\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Accuracy: {:.2%}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() \n",
    "model.add(Embedding(vocab_size, 300, input_length=max_length)) \n",
    "model.add(LSTM(100)) \n",
    "model.add(Dense(1, activation='sigmoid')) \n",
    "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy']) \n",
    "\n",
    "print(model.summary())\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, epochs=50, verbose=0)\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Accuracy: {:.2%}'.format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
